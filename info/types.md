# Type Inference in frawk

frawk has a different approach to types than Awk. In some Awk implementations,
the word "type" is sometimes used to indicate if a variable is a scalar or an
array. A given variable cannot be both a scalar and an array, so in Awk the
program

```
$ awk 'BEGIN { x=1; x[2]=3; }'
```

Yields an error:

> awk: cmd. line:1: fatal: attempt to use scalar `x' as an array.

This is in contrast to a language like (say) Python, where the dynamic type of a
variable is free to change arbitrarily over the course of its lifetime. Unlike
languages like Rust or C, however, a variable can freely change the "kind of
scalar" that it happens to be, so the following program yields "4 hello":

```
$ awk 'BEGIN { x="hello"; y=x; x=4; print x, y}'
```

There are several ways to go about implementing this, but one good model is to
treat an Awk scalar as though it contains either a string or a floating point
number (there is room for a null value and an integer here as well, but let's
stick to 2). Numeric and string values are automatically coerced into one
another depending on the context, so it can be hard to observe which sort of
value a variable is at any given time.

One goal of frawk is to provide performance competitive with the equivalent
script written in Rust. To further this goal, features along these lines would
be nice:

1. Allow common numeric computations to be compiled to fast loops on integer of
   floating-point values.
2. Make coercions explicit in generated bytecode.
3. Detect maps with all-integer keys and avoid string conversions for them.

These factors aren't just desirable because they remove runtime type checks.
They also make it easier for the compiler (LLVM in our case) to optimize the
code. For example, we can teach LLVM that a string to int conversion is
read-only, and it will elide redundant conversions when it feels it can.

The standard tactic for achieving these goals in a "dynamic" language is to
write a [tracing JIT](https://en.wikipedia.org/wiki/Tracing_just-in-time_compilation)
compiler. This approach lets you generate custom code based on the type a
variable has _in practice_. While this approach has been quite successful for
languages like JavaScript, I think it may be overkill for a language like Awk,
which is a lot simpler.

This document describes frawk's approach to types: it gives the language a
relatively "static" execution model while still maintaining most of Awk's
semantics around variable assignment. frawk does this by combining a heuristic
(SSA form) with a custom inference algorithm. The end result is a type
inference mechanism which provides _safe approximation_ of the types a
traditional dynamic implementation would exhibit at runtime.

## SSA Form

[Static Single
Assignment](https://en.wikipedia.org/wiki/Static_single_assignment_form) (SSA)
form is a popular compiler intermediate representation. Without getting into too
many details, SSA conversion transforms programs that look like:

```
x = "string"
x = 3
```
Into programs like:
```
x0 = "string"
x1 = 3
```

SSA typically handles control flow by decomposing a program into "basic blocks"
of branch-free instructions along with (potentially conditional) jumps to other
basic blocks. These basic blocks and branches form a directed graph called a
[Control Flow Graph](https://en.wikipedia.org/wiki/Control-flow_graph). The
value of a variable might depend on the path used to reach the basic block where
the assignment takes place, for that SSA has the notion of a phi function. So we
might translate the following program:

```
x = 0
if (x) {
    x = 3
} else {
    x = 7
}
print x
```

Into the following SSA:
```
0:
    x0 = 0
    # If x0, jump to label 1, otherise jump to label 2
    brif x0 1: 2:
1:
    x1 = 3
    jmp 3:
2:
    x2 = 7
    jmp 3:
3:
    x3 = phi[1: x1, 2: x2]
    print(x3)
```

SSA makes a lot of things easier, but the initial motivation for transforming
frawk programs to SSA is that it breaks up assignments of multiple scalar
types, so the program `x=1; x="hello"` turns into an assignment to two separate
variables. While this conversion allows us to model some programs more
precisely, it doesn't work in all cases. For one thing, we cannot perform this
same conversion on global variables (except for the ones that are only accessed
from the main loop), or to the types of map keys and values.  It also doesn't
help if variables with different types land in the same "phi" node (e.g. `x = y
? "z" : 3`). In these cases, frawk has rules for approximating the type: e.g.
`x = 3; x="x"` with `x` global will give `x` a static type of "string".

To see the untyped SSA output for a frawk program, pass the `--dump-cfg` flag.

## Type Inference

Once a program is in SSA form, frawk still has to pick types for all the
variables and insert coercions where a variable is used in a context not
matching its type. The former task is harder than the latter.

For example, `+` in Awk is only ever numeric. The expressions `"3"+2.0` and `3+2.0`
both evaluate to `5.0`. But once frawk knows that "3" is a string, it isn't too
hard to figure out that it should be coerced to a floating point value before
addition.

In my experience, [type
infererence](https://papl.cs.brown.edu/2017/Type_Inference.html) usually refers to
unification-based algorithms for
[Damas-Hindley-Milner](https://en.wikipedia.org/wiki/Hindley%E2%80%93Milner_type_system)-esque
systems. I recommend the links in this paragraph for a more careful exposition,
but for a hint about how these algorithms work, consider this program:

```
x = 1
y = x
z = y
x = z
```

### Equality Constraints

A classic inference algorithm applies a constraint after each line here. The
first line will constrain `x` to have some numeric type (depending on your
language).  The next three lines will introduce _equality constraints_: e.g.
line 3 will constrain any assignment of types to variables to assign the same
type to variable `z` and to variable `y`. You can extend HM-type algorithms to
compute the approximations from the previous section (e.g. `x=3;x="z"` could be
resolved to "x has the type `Number or String`"), but the fact that it only
supports equality constraints appears to be a constant.

The issue with equality constraints is that type information flows in both
directions. When I write `x=y`, anything I learn about the types for `y` will
flow into types for `x` _and vice-versa_. We want to avoid that for frawk:
consider the following cases (supposing that SSA cannot help us "split" these
variables).

```
y = 3
x = "string"
x = y
```

We have to pessimize `x` to have type "string" here, but `y` is only ever
assigned to integer values. If we unified the types of `x` and `y` we would
have to pessimize `y` as well. The same principle applies to loading and
storing into a map. This particular example can seem contrived, but as the
program grows in size, it can become increasingly difficult to maintain numeric
variables if having a string on either side of an assignment "infects" both
sides.

### Information Flow

frawk's type inference algorithm gives assignment to scalar variables
_unidirectional_ information flow. In the example from before:

```
y = 3
x = "string"
x = y
```

Line 1 introduces a "flows" constraint from `Integer` into `y`, from `String`
into `x` and from `y` into `x`. These are modelled as directed edges in a graph:
the type of a particular variable is taken as the "most general" of all its incoming
edges: `Integer` and `Float` is approximated as `Float`, and `String` is
considered more general than anything else. Note that unification is a special
case of this model, where "flows" constraints are added in both directions. This
is how map assignment is implemented.

This is the core of how frawk's type inference works: it wires up a directed
graph and runs the "flows" rule until the values in the graph's nodes stop
changing. This is slower than unification-based algorithms (which get to use
union-find, which provides an efficient mechanism for iteratively shrinking
this graph), but essentially all of the Awk programs I write are mercifully
short, so this hasn't been much a of problem.

> Note: This distinction between bidirectional and unidirectional constraints,
> where the former is more efficient to implement while the latter is more
> precise, shows up elsewhere in static analysis. For example, see the
> difference between Andersen's and Steensgaard's points-to analyses, detailed
> in [this book](https://cs.au.dk/~amoeller/spa/).

> Note: As we do more static analysis in frawk, it would be worth looking into a
> replacement for this system based on [Abstracting Definitional
> Interpreters](https://arxiv.org/abs/1707.04755). I've played around with
> implementing this in Rust, but I found that it was a lot harder to get the
> pluggable, nested effects right than it appears to be in Racket or Haskell.
> One of these days I'll try again.

### Other Subtleties

To get this idea to handle the entire awk language we need to add more
constraints and more rules. The [full
implementation](https://github.com/ezrosent/frawk/blob/master/src/types.rs) is
currently the best source on how all the given pieces fit together. This section
gives a feel for what else is going on to get this working.

**More Rules** Maps have rules that act like "flows", but only on the key type
and map type of their value. User-defined functions have rules that encode the
ordering of their arguments (giving the graph hyperedges).

**Dependent Return Types** frawk also has to encode "business logic" in its
rules for some builtin functions. For example the type of `a + b` depends on the
type of `a` and the type of `b`: adding an integer to an integer produces an
integer, but adding a string to an integer produces a floating point value (as
strings may contain non-integer numbers), and adding a float to an integer
produces an integer (by convention). Luckily, these rules can be implemented in
such a way that their values do not "oscillate" in unexpected ways, allowing the
analysis to converge. This "domain-specific" logic is present in the
[builtins](https://github.com/ezrosent/frawk/blob/master/src/builtins.rs)
module.

Furthermore, all of these subtleties are in play when handling user-defined
functions. We use some standard techniques to (a) essentially copy the function
body for each unique invocation and (b) cache recursive invocations in a way
that doesn't result in (too much) over-approximation when it comes to types.

